{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Evaluation\n",
    "\n",
    "This notebook contains code for evaluating agent performance using LLM-as-a-judge.\n",
    "We evaluate logged agent interactions against a quality checklist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic-ai in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (1.0.15)\n",
      "Requirement already satisfied: pydantic-ai-slim==1.0.15 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.0.15)\n",
      "Requirement already satisfied: genai-prices>=0.0.28 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.0.29)\n",
      "Requirement already satisfied: griffe>=1.3.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.14.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.37.0)\n",
      "Requirement already satisfied: pydantic-graph==1.0.15 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.0.15)\n",
      "Requirement already satisfied: pydantic>=2.10 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.11.9)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: ag-ui-protocol>=0.1.8 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.1.9)\n",
      "Requirement already satisfied: starlette>=0.45.3 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.48.0)\n",
      "Requirement already satisfied: anthropic>=0.69.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.69.0)\n",
      "Requirement already satisfied: boto3>=1.39.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.40.43)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.6.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.0.52)\n",
      "Requirement already satisfied: pyperclip>=1.9.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.11.0)\n",
      "Requirement already satisfied: rich>=13 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (14.1.0)\n",
      "Requirement already satisfied: cohere>=5.18.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (5.18.0)\n",
      "Requirement already satisfied: pydantic-evals==1.0.15 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.0.15)\n",
      "Requirement already satisfied: google-genai>=1.31.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.39.1)\n",
      "Requirement already satisfied: groq>=0.25.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.32.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.5 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.35.3)\n",
      "Requirement already satisfied: logfire>=3.14.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.10.0)\n",
      "Requirement already satisfied: mcp>=1.12.3 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.15.0)\n",
      "Requirement already satisfied: mistralai>=1.9.10 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.9.10)\n",
      "Requirement already satisfied: openai>=1.107.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (9.1.2)\n",
      "Requirement already satisfied: temporalio==1.18.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.18.0)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.41.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.32.5)\n",
      "Requirement already satisfied: anyio>=0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-evals==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.11.0)\n",
      "Requirement already satisfied: logfire-api>=3.14.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-evals==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.10.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-evals==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (6.0.3)\n",
      "Requirement already satisfied: nexus-rpc==1.1.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.1.0)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=3.20 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (6.32.1)\n",
      "Requirement already satisfied: types-protobuf>=3.20 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (6.32.1.20250918)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.2.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic>=2.10->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic>=2.10->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.33.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from anthropic>=0.69.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.9.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from anthropic>=0.69.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.17.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from anthropic>=0.69.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from anthropic>=0.69.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from anyio>=0->pydantic-evals==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: certifi in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.16.0)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.43 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.40.43)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from botocore<1.41.0,>=1.40.43->boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from botocore<1.41.0,>=1.40.43->boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.43->boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.12.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.22.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.32.4.20250913)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.4.3)\n",
      "Requirement already satisfied: filelock in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.1.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from google-genai>=1.31.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (15.0.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from griffe>=1.3.2->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.4.6)\n",
      "Requirement already satisfied: aiohttp in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.12.15)\n",
      "Requirement already satisfied: executing>=2.0.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<1.38.0,>=1.35.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation>=0.41b0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<1.38.0,>=1.35.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.37.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-http<1.38.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-http<1.38.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-http<1.38.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.37.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==1.0.15->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-sdk<1.38.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-httpx>=0.42b0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.58b0)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (3.0.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.37.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.27.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.2.2)\n",
      "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.2.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation>=0.41b0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.58b0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation-httpx>=0.42b0->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.58b0)\n",
      "Requirement already satisfied: wcwidth in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.2.14)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pydantic-settings>=2.5.2->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: click>=7.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from uvicorn>=0.31.1->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (8.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.0.15->pydantic-ai) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/data/Github/7-Day-AI-Agents-Email-Crash-Course/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install pydantic-ai\n",
    "%pip install python-dotenv\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded: sk-pro...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not found. Set it in .env file.\")\n",
    "\n",
    "print(\"API Key loaded:\", OPENAI_API_KEY[:6] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluation Schema\n",
    "\n",
    "We define the structure for evaluation results using Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationCheck(BaseModel):\n",
    "    check_name: str\n",
    "    justification: str\n",
    "    check_pass: bool\n",
    "\n",
    "class EvaluationChecklist(BaseModel):\n",
    "    checklist: list[EvaluationCheck]\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evaluation Agent (LLM as Judge)\n",
    "\n",
    "The evaluation agent uses a detailed prompt to assess agent responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = \"\"\"\n",
    "Use this checklist to evaluate the quality of an AI agent's answer (<ANSWER>) to a user question (<QUESTION>).\n",
    "We also include the entire log (<LOG>) for analysis.\n",
    "\n",
    "For each item, check if the condition is met.\n",
    "\n",
    "Checklist:\n",
    "- instructions_follow: The agent followed the user's instructions (in <INSTRUCTIONS>)\n",
    "- instructions_avoid: The agent avoided doing things it was told not to do\n",
    "- answer_relevant: The response directly addresses the user's question\n",
    "- answer_clear: The answer is clear and correct\n",
    "- answer_citations: The response includes proper citations or sources when required\n",
    "- completeness: The response is complete and covers all key aspects of the request\n",
    "- tool_call_search: Is the search tool invoked?\n",
    "\n",
    "Output true/false for each check and provide a short explanation for your judgment.\n",
    "\"\"\".strip()\n",
    "\n",
    "eval_agent = Agent(\n",
    "    name='eval_agent',\n",
    "    model='gpt-4o-mini',\n",
    "    instructions=evaluation_prompt,\n",
    "    output_type=EvaluationChecklist\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Log Files\n",
    "\n",
    "Load the agent interaction logs that we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = Path('../logs')\n",
    "\n",
    "def load_log_file(log_file):\n",
    "    \"\"\"Load a JSON log file and add the filename to the record.\"\"\"\n",
    "    with open(log_file, 'r', encoding='utf-8') as f:\n",
    "        log_data = json.load(f)\n",
    "        log_data['log_file'] = str(log_file)\n",
    "        return log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 log files for evaluation\n"
     ]
    }
   ],
   "source": [
    "# Collect all AI-generated logs for a specific agent version\n",
    "agent_name = 'gh_agent'  # or 'faq_agent_v2', etc.\n",
    "eval_set = []\n",
    "\n",
    "for log_file in LOG_DIR.glob('*.json'):\n",
    "    if agent_name not in log_file.name:\n",
    "        continue\n",
    "\n",
    "    log_record = load_log_file(log_file)\n",
    "    \n",
    "    # Only evaluate AI-generated test data (or use 'user' for user interactions)\n",
    "    if log_record.get('source') == 'user':\n",
    "        eval_set.append(log_record)\n",
    "\n",
    "print(f\"Loaded {len(eval_set)} log files for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify Log Messages\n",
    "\n",
    "Remove unnecessary details from logs to reduce token usage during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_log_messages(messages):\n",
    "    \"\"\"Simplify log messages by removing unnecessary metadata.\"\"\"\n",
    "    log_simplified = []\n",
    "\n",
    "    for m in messages:\n",
    "        parts = []\n",
    "    \n",
    "        for original_part in m['parts']:\n",
    "            part = original_part.copy()\n",
    "            kind = part['part_kind']\n",
    "    \n",
    "            if kind == 'user-prompt':\n",
    "                del part['timestamp']\n",
    "            if kind == 'tool-call':\n",
    "                del part['tool_call_id']\n",
    "            if kind == 'tool-return':\n",
    "                del part['tool_call_id']\n",
    "                del part['metadata']\n",
    "                del part['timestamp']\n",
    "                # Replace actual search results with placeholder to save tokens\n",
    "                part['content'] = 'RETURN_RESULTS_REDACTED'\n",
    "            if kind == 'text':\n",
    "                del part['id']\n",
    "    \n",
    "            parts.append(part)\n",
    "    \n",
    "        message = {\n",
    "            'kind': m['kind'],\n",
    "            'parts': parts\n",
    "        }\n",
    "    \n",
    "        log_simplified.append(message)\n",
    "    return log_simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Evaluation Prompt\n",
    "\n",
    "Format the log records into the evaluation prompt structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_format = \"\"\"\n",
    "<INSTRUCTIONS>{instructions}</INSTRUCTIONS>\n",
    "<QUESTION>{question}</QUESTION>\n",
    "<ANSWER>{answer}</ANSWER>\n",
    "<LOG>{log}</LOG>\n",
    "\"\"\".strip()\n",
    "\n",
    "def format_evaluation_prompt(log_record):\n",
    "    \"\"\"Format a log record into an evaluation prompt.\"\"\"\n",
    "    instructions = log_record['system_prompt']\n",
    "    \n",
    "    # Extract question from first message\n",
    "    question = log_record['messages'][0]['parts'][0]['content']\n",
    "    \n",
    "    # Extract answer from last message\n",
    "    answer = log_record['messages'][-1]['parts'][0]['content']\n",
    "    \n",
    "    # Simplify and serialize log\n",
    "    simplified_messages = simplify_log_messages(log_record['messages'])\n",
    "    log = json.dumps(simplified_messages)\n",
    "    \n",
    "    return user_prompt_format.format(\n",
    "        instructions=instructions,\n",
    "        question=question,\n",
    "        answer=answer,\n",
    "        log=log\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Evaluate each log record using the evaluation agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_log_record(log_record):\n",
    "    \"\"\"Evaluate a single log record.\"\"\"\n",
    "    user_prompt = format_evaluation_prompt(log_record)\n",
    "    result = await eval_agent.run(user_prompt, output_type=EvaluationChecklist)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28c961686d44819a67798a5cb40f572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating logs:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed evaluation of 9 interactions\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for log_record in tqdm(eval_set, desc=\"Evaluating logs\"):\n",
    "    eval_result = await evaluate_log_record(log_record)\n",
    "    eval_results.append((log_record, eval_result))\n",
    "\n",
    "print(f\"\\nCompleted evaluation of {len(eval_results)} interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Results into DataFrame\n",
    "\n",
    "Convert evaluation results into a pandas DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "instructions_follow",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "instructions_avoid",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "answer_relevant",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "answer_clear",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "answer_citations",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "completeness",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "tool_call_search",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a00352f7-447a-4a6e-ae1e-970e09562d3f",
       "rows": [
        [
         "0",
         "gh_agent_20251003_223237_2efc1f.json",
         "what requirements i need to join?",
         "It seems there isn't a direct answer regarding the specific requirements to join a course in the search results. However, here are some general guidelines that can often apply:\n\n1. **Registration**: You typically need to register for the course before the start date. It might involve filling out a form or signing up through a specific link provided by the course organizers.\n\n2. **Prerequisites**: Check if the course has any prerequisites in terms of technical skills or knowledge. \n\n3. **Materials**: Some courses may require you to have specific software or tools installed, such as Python, Anaconda, or other relevant tools, depending on the course content.\n\n4. **Commitment to Deadlines**: Be prepared to adhere to deadlines for homework submissions and project completions, as this may impact your ability to receive certification or course credit.\n\nFor the exact requirements and details, you might want to check the official course page or contact the course administrators directly.\n\nIf you need more specific details about a certain course or aspect, feel free to ask!",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "The agent's response failed to follow the instructions regarding the use of the search tool effectively, did not provide specific requirements from the course materials, and lacked the necessary citations."
        ],
        [
         "1",
         "gh_agent_20251003_223314_864384.json",
         "what course you offer?",
         "The course offered is the **Data Engineering Zoomcamp**, which is set to start on **January 13th, 2025**. Here are some key details:\n\n- **Registration**: You can register before the course starts using [this link](https://airtable.com/shr6oVXeQvSI5HuWD).\n- **Communication**: Join the [course Telegram channel](https://t.me/dezoomcamp) for announcements and updates.\n- **Prerequisites**: To get the most out of the course, you should have basic coding experience, familiarity with SQL, and experience with Python is helpful but not required. No prior data engineering experience is necessary. More details on prerequisites can be found in the [Readme on GitHub](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/README.md#prerequisites).\n\nIts also noted that materials will be available for self-paced learning after the course finishes, but certificates are only awarded for participation in the live cohort.\n\nFor further information, you can refer to the specific documentation:\n- [Course Start Date](https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/general/001_9e508f2212_course-when-does-the-course-start.md)\n- [Course Prerequisites](https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/general/002_bfafa427b3_course-what-are-the-prerequisites-for-this-course.md)\n- [Self-paced Learning](https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/general/008_068529125b_course-can-i-follow-the-course-after-it-finishes.md)\n- [Certificate Information](https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/general/015_900f60fd25_certificate-can-i-follow-the-course-in-a-self-pace.md)",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "The agent's answer is comprehensive, relevant, and adheres to the provided instructions."
        ],
        [
         "2",
         "gh_agent_20251003_233528_7c5fd3.json",
         "hi",
         "Hello! How can I assist you today?",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "The agent did not follow the instructions to use the search tool for relevant documentation, resulting in an inadequate response."
        ],
        [
         "3",
         "gh_agent_20251004_004211_2ac759.json",
         "what due date to register?",
         "I couldn't find specific information about the registration due date in the course materials. However, I recommend checking the official course page or syllabus for exact deadlines, as these details are often provided there. If you have further questions, feel free to ask!",
         "True",
         "True",
         "True",
         "True",
         "False",
         "False",
         "True",
         "The agent followed the instructions and made an attempt to provide a answer by searching for relevant information. However, it failed to provide a citation and deliver a complete answer."
        ],
        [
         "4",
         "gh_agent_20251004_025044_c9ba1b.json",
         "hello",
         "Hello! How can I assist you today?",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "The agent's response fails to follow several key instructions, particularly regarding the use of the search tool and the provision of documentation-related guidance."
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>instructions_follow</th>\n",
       "      <th>instructions_avoid</th>\n",
       "      <th>answer_relevant</th>\n",
       "      <th>answer_clear</th>\n",
       "      <th>answer_citations</th>\n",
       "      <th>completeness</th>\n",
       "      <th>tool_call_search</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh_agent_20251003_223237_2efc1f.json</td>\n",
       "      <td>what requirements i need to join?</td>\n",
       "      <td>It seems there isn't a direct answer regarding...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>The agent's response failed to follow the inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gh_agent_20251003_223314_864384.json</td>\n",
       "      <td>what course you offer?</td>\n",
       "      <td>The course offered is the **Data Engineering Z...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The agent's answer is comprehensive, relevant,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gh_agent_20251003_233528_7c5fd3.json</td>\n",
       "      <td>hi</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not follow the instructions to u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh_agent_20251004_004211_2ac759.json</td>\n",
       "      <td>what due date to register?</td>\n",
       "      <td>I couldn't find specific information about the...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>The agent followed the instructions and made a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gh_agent_20251004_025044_c9ba1b.json</td>\n",
       "      <td>hello</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's response fails to follow several k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file                           question  \\\n",
       "0  gh_agent_20251003_223237_2efc1f.json  what requirements i need to join?   \n",
       "1  gh_agent_20251003_223314_864384.json             what course you offer?   \n",
       "2  gh_agent_20251003_233528_7c5fd3.json                                 hi   \n",
       "3  gh_agent_20251004_004211_2ac759.json         what due date to register?   \n",
       "4  gh_agent_20251004_025044_c9ba1b.json                              hello   \n",
       "\n",
       "                                              answer  instructions_follow  \\\n",
       "0  It seems there isn't a direct answer regarding...                False   \n",
       "1  The course offered is the **Data Engineering Z...                 True   \n",
       "2                 Hello! How can I assist you today?                False   \n",
       "3  I couldn't find specific information about the...                 True   \n",
       "4                 Hello! How can I assist you today?                False   \n",
       "\n",
       "   instructions_avoid  answer_relevant  answer_clear  answer_citations  \\\n",
       "0                True            False         False             False   \n",
       "1                True             True          True              True   \n",
       "2                True            False          True             False   \n",
       "3                True             True          True             False   \n",
       "4                True            False          True             False   \n",
       "\n",
       "   completeness  tool_call_search  \\\n",
       "0         False              True   \n",
       "1          True              True   \n",
       "2         False             False   \n",
       "3         False              True   \n",
       "4         False             False   \n",
       "\n",
       "                                             summary  \n",
       "0  The agent's response failed to follow the inst...  \n",
       "1  The agent's answer is comprehensive, relevant,...  \n",
       "2  The agent did not follow the instructions to u...  \n",
       "3  The agent followed the instructions and made a...  \n",
       "4  The agent's response fails to follow several k...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for log_record, eval_result in eval_results:\n",
    "    messages = log_record['messages']\n",
    "    \n",
    "    row = {\n",
    "        'file': Path(log_record['log_file']).name,\n",
    "        'question': messages[0]['parts'][0]['content'],\n",
    "        'answer': messages[-1]['parts'][0]['content'],\n",
    "    }\n",
    "    \n",
    "    # Extract check results\n",
    "    checklist = eval_result.output\n",
    "    checks = {c.check_name: c.check_pass for c in checklist.checklist}\n",
    "    row.update(checks)\n",
    "    \n",
    "    # Add summary\n",
    "    row['summary'] = checklist.summary\n",
    "    \n",
    "    rows.append(row)\n",
    "\n",
    "df_evals = pd.DataFrame(rows)\n",
    "df_evals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics\n",
    "\n",
    "Calculate overall pass rates for each evaluation criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "==================================================\n",
      "instructions_follow: 44.4% pass\n",
      "instructions_avoid: 100.0% pass\n",
      "answer_relevant: 44.4% pass\n",
      "answer_clear: 77.8% pass\n",
      "answer_citations: 22.2% pass\n",
      "completeness: 22.2% pass\n",
      "tool_call_search: 55.6% pass\n",
      "==================================================\n",
      "Overall Pass Rate: 52.4%\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean pass rate for each check\n",
    "check_columns = [\n",
    "    'instructions_follow',\n",
    "    'instructions_avoid',\n",
    "    'answer_relevant',\n",
    "    'answer_clear',\n",
    "    'answer_citations',\n",
    "    'completeness',\n",
    "    'tool_call_search'\n",
    "]\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"=\" * 50)\n",
    "if df_evals.empty:\n",
    "    print(\"No evaluation results available.\")\n",
    "else:\n",
    "    for col in check_columns:\n",
    "        if col in df_evals.columns:\n",
    "            pass_rate = df_evals[col].mean() * 100\n",
    "            print(f\"{col}: {pass_rate:.1f}% pass\")\n",
    "    # Overall pass rate\n",
    "    existing_cols = [col for col in check_columns if col in df_evals.columns]\n",
    "    if existing_cols:\n",
    "        overall_pass_rate = df_evals[existing_cols].mean().mean() * 100\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Overall Pass Rate: {overall_pass_rate:.1f}%\")\n",
    "    else:\n",
    "        print(\"No check columns found in evaluation results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the evaluation results to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation results to ../logs/evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = Path('../logs/evaluation_results.csv')\n",
    "df_evals.to_csv(output_path, index=False)\n",
    "print(f\"Saved evaluation results to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Failed Checks\n",
    "\n",
    "Examine interactions that failed specific checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 7 interactions without proper citations:\n",
      "                            question  \\\n",
      "0  what requirements i need to join?   \n",
      "2                                 hi   \n",
      "3         what due date to register?   \n",
      "4                              hello   \n",
      "5                                 yo   \n",
      "\n",
      "                                              answer  \n",
      "0  It seems there isn't a direct answer regarding...  \n",
      "2                 Hello! How can I assist you today?  \n",
      "3  I couldn't find specific information about the...  \n",
      "4                 Hello! How can I assist you today?  \n",
      "5                 Hello! How can I assist you today?  \n"
     ]
    }
   ],
   "source": [
    "# Show interactions that failed answer_citations check\n",
    "if 'answer_citations' in df_evals.columns:\n",
    "\tfailed_citations = df_evals[df_evals['answer_citations'] == False]\n",
    "\tprint(f\"\\nFound {len(failed_citations)} interactions without proper citations:\")\n",
    "\tprint(failed_citations[['question', 'answer']].head())\n",
    "else:\n",
    "\tprint(\"No 'answer_citations' column found in evaluation results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Quality Evaluation (Optional)\n",
    "\n",
    "Evaluate the search function using information retrieval metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_search_quality(search_function, test_queries):\n",
    "    \"\"\"\n",
    "    Evaluate search function using Hit Rate and MRR (Mean Reciprocal Rank).\n",
    "    \n",
    "    Args:\n",
    "        search_function: Function that takes a query and returns search results\n",
    "        test_queries: List of (query, expected_docs) tuples\n",
    "    \n",
    "    Returns:\n",
    "        List of evaluation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for query, expected_docs in test_queries:\n",
    "        search_results = search_function(query, num_results=5)\n",
    "        \n",
    "        # Calculate hit rate\n",
    "        relevant_found = any(doc['filename'] in expected_docs for doc in search_results)\n",
    "        \n",
    "        # Calculate MRR\n",
    "        mrr = 0\n",
    "        for i, doc in enumerate(search_results):\n",
    "            if doc['filename'] in expected_docs:\n",
    "                mrr = 1 / (i + 1)\n",
    "                break\n",
    "            \n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'hit': relevant_found,\n",
    "            'mrr': mrr\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# test_queries = [\n",
    "#     (\"Can I join the course now?\", [\"003_3f1424af17_course-can-i-still-join-the-course-after-the-start.md\"]),\n",
    "#     # Add more test queries...\n",
    "# ]\n",
    "# search_results = evaluate_search_quality(faq_index.search, test_queries)\n",
    "# df_search = pd.DataFrame(search_results)\n",
    "# print(f\"Hit Rate: {df_search['hit'].mean():.2%}\")\n",
    "# print(f\"Mean MRR: {df_search['mrr'].mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
